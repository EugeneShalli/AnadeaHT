{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6d23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b3171",
   "metadata": {},
   "source": [
    "### Reading TRAIN, VAL, TEST JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e473f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_annotations(train_path: str, val_path: str, test_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Reading Json annotations of LIVECell Dataset.\n",
    "    \"\"\"\n",
    "    print('Reading train')\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_annotations = json.load(f)\n",
    "#         print(type(train_annotations))\n",
    "        \n",
    "\n",
    "    print('Reading val')\n",
    "    with open(val_path, 'r') as f:\n",
    "        val_annotations = json.load(f)\n",
    "\n",
    "    print('Reading test')    \n",
    "    with open(test_path, 'r') as f:\n",
    "        test_annotations = json.load(f)\n",
    "        \n",
    "    return [train_annotations, val_annotations, test_annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e35928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train\n",
      "Reading val\n",
      "Reading test\n"
     ]
    }
   ],
   "source": [
    "train_json_path = '/workspace/annotations/LIVECell/livecell_coco_train.json'\n",
    "val_json_path = '/workspace/annotations/LIVECell/livecell_coco_val.json'\n",
    "test_json_path = '/workspace/annotations/LIVECell/livecell_coco_test.json'\n",
    "\n",
    "# train_annotations, val_annotations, test_annotations\n",
    "annotations = read_json_annotations(train_json_path, val_json_path, test_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b3719c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_decode(mask):\n",
    "    array = np.zeros((520, 704))\n",
    "    for label in mask:\n",
    "        s = label.split()\n",
    "        starts = list(map(lambda x: int(x) - 1, s[0::2]))\n",
    "        lengths = list(map(int, s[1::2]))\n",
    "        ends = [x + y for x, y in zip(starts, lengths)]\n",
    "        img = np.zeros((520*704), dtype=np.float32)            \n",
    "        for start, end in zip(starts, ends):\n",
    "            img[start : end] = 1 \n",
    "        array += img.reshape((520, 704))\n",
    "    return array.clip(0, 1)\n",
    "\n",
    "def rle_encode(img):\n",
    "    \"\"\" TBD\n",
    "    \n",
    "    Args:\n",
    "        img (np.array): \n",
    "            - 1 indicating mask\n",
    "            - 0 indicating background\n",
    "    \n",
    "    Returns: \n",
    "        run length as string formated\n",
    "    \"\"\"\n",
    "    \n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "PatientInfoTuple = namedtuple(\n",
    "    'PatientInfoTuple',\n",
    "    'id, cell_type, annotations'\n",
    ")\n",
    "\n",
    "def getPatientsInfo():\n",
    "    df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')\n",
    "    patientsInfo_list = list()\n",
    "    \n",
    "    for id in df.id.unique():\n",
    "        cell_type = df[df.id == id].cell_type.unique()[0]\n",
    "        annotations = df[df[\"id\"] == id][\"annotation\"].tolist()\n",
    "        \n",
    "        patientsInfo_list.append(PatientInfoTuple(\n",
    "            id,\n",
    "            cell_type,\n",
    "            annotations\n",
    "        ))\n",
    "        \n",
    "    return patientsInfo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = list()\n",
    "array_help = df[df['image_id']==1564017][\"polygons\"].to_numpy()\n",
    "# print(type(df[df['image_id']=='1564017']['polygons']))\n",
    "print(type(array_help[0]))\n",
    "for img_mask in array_help:\n",
    "#     print(type(img_mask))\n",
    "#     print(img_mask)\n",
    "    img_mask = img_mask[2:-2]\n",
    "    img_mask = np.array(img_mask.split())\n",
    "    print(type(img_mask))\n",
    "\n",
    "    x = img_mask[0::2]\n",
    "    y = img_mask[1::2]\n",
    "    \n",
    "    arr = [(x, y) for (x, y) in zip(y,x)]\n",
    "    vertices = np.asarray(arr)\n",
    "    path = Path(vertices)\n",
    "    xmin, ymin, xmax, ymax = np.asarray(path.get_extents(), dtype=int).ravel()\n",
    "    x, y = np.mgrid[:520, :704]\n",
    "    \n",
    "    # mesh grid to a list of points\n",
    "    points = np.vstack((x.ravel(), y.ravel())).T\n",
    "\n",
    "    # select points included in the path\n",
    "    mask = path.contains_points(points)\n",
    "    path_points = points[np.where(mask)]\n",
    "\n",
    "    # reshape mask for display\n",
    "    img_mask = mask.reshape(x.shape)\n",
    "    img_mask = img_mask.astype(np.int)\n",
    "    # ENCODED MASK\n",
    "    encoded_img_mask = rle_encode(img_mask)\n",
    "    seg_list.append(encoded_img_mask)\n",
    "\n",
    "\n",
    "seg_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a82291e",
   "metadata": {},
   "source": [
    "### Convert JSON to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Add info about data of creation of sample and other important info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_livecell_df_rows(annotations :list[dict], subsets :list[str]=['train', 'val', 'test']) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Create LIVECell List{Dict], where:\n",
    "    \n",
    "    'image_id': id of an image in the dataset\n",
    "    'cell_type': name of cell type\n",
    "    'width': width of an image\n",
    "    'height': hitht of an image\n",
    "    'file_name': file name of an image\n",
    "    'file_path': absolute path to the image file\n",
    "    'annotation_id': id of one (current) cell\n",
    "    'category_id': cell class\n",
    "    'polygons': segmentation polygons\n",
    "    'area': area of a polygon\n",
    "    'bbox': bounding box of a cell\n",
    "    \"\"\"\n",
    "    df_rows = []\n",
    "\n",
    "    for idx, (data, subset) in enumerate(zip(tqdm(annotations), subsets)):\n",
    "#         print(f'idx: {idx}, subset: {subset}')\n",
    "    \n",
    "        # Image Id to Image\n",
    "        image_id2_image_dict = dict()\n",
    "        for image in data['images']:\n",
    "            image_id2_image_dict[image['id']] = image\n",
    "    \n",
    "        for annotation in tqdm(data['annotations']):\n",
    "            image_id = annotation['image_id']\n",
    "            image = image_id2_image_dict.get(image_id)\n",
    "            # Image File Path\n",
    "            file_name = image['file_name']\n",
    "            file_name_split = file_name.split('_')\n",
    "            cell_type = file_name_split[0]\n",
    "            well = file_name_split[2]\n",
    "            location = file_name_split[3]\n",
    "            timestamp = file_name_split[4]\n",
    "            crop = file_name_split[5][0]\n",
    "            if subset in ['train', 'val']:\n",
    "                file_path = f'/workspace/images/livecell_train_val_images/{file_name}'\n",
    "            else:\n",
    "                file_path = f'/workspace/images/livecell_test_images/{file_name}'\n",
    "            \n",
    "            df_rows.append({\n",
    "                'image_id': np.int32(image['id']),\n",
    "                'cell_type': cell_type,\n",
    "#                 'well': well,\n",
    "#                 'location': location,\n",
    "#                 'timestamp': timestamp,\n",
    "#                 'crop': crop,\n",
    "#                 'well_time': well + '_' + timestamp,\n",
    "#                 'well_time_loc': well + '_' + timestamp + '_' + location,\n",
    "#                 'well_time_loc_crop': well + '_' + timestamp + '_' + location + '_' + crop,\n",
    "                'width': np.int16(image['width']),\n",
    "                'height': np.int16(image['height']),\n",
    "                'file_name': file_name,\n",
    "#                 'file_path': file_path,\n",
    "                'annotation_id': np.int32(annotation['id']),\n",
    "                'category_id': np.int8(annotation['category_id']),\n",
    "                'polygons': np.array(annotation['segmentation'], dtype=np.float32),\n",
    "#                 'annotation': encoded_img_mask,\n",
    "                'area': np.float32(annotation['area']),\n",
    "                'bbox': np.array(annotation['bbox'], dtype=np.float32),\n",
    "                'original_split': subset,\n",
    "            })\n",
    "    \n",
    "    return df_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043533c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rows = create_livecell_df_rows(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrame\n",
    "df = pd.DataFrame.from_dict(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce090a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of annotated images\n",
    "len(df['image_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['well_time_loc_crop'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['well']=='A3'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crop'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell Type to Label Dictionary, \"+ 1\" sine 0 is reserved for background\n",
    "CELL_TYPE2LABEL = dict([(name, i + 1) for i, name in enumerate(CELL_TYPES)])\n",
    "df['label'] = df['cell_type'].apply(CELL_TYPE2LABEL.get).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a959e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f173a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['label'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('livecell_base_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605504b9",
   "metadata": {},
   "source": [
    "## Bbox Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea23777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('livecell_base_preprocessing_rle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5292938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bbox\"] = df[\"bbox\"].str[1:-1]\n",
    "# [364.5894775390625, 798.4615478515625, 383.0497131347656, 798.4615478515625]\n",
    "df['bbox_sanity'] = df['bbox'].apply(lambda x: True if float(x.split()[2])/3 > 1 or float(x.split()[3])/3 > 1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77e6cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1662447\n",
       "unique          2\n",
       "top          True\n",
       "freq      1662442\n",
       "Name: bbox_sanity, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bbox_sanity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569ccb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
