{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c07886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/inversion/run-length-decoding-quick-start\n",
    "def rle_decode(mask_rle, shape, color=1):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height, width, channels) of array to return\n",
    "    color: color for the mask\n",
    "    Returns numpy array (mask)\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "\n",
    "    starts = list(map(lambda x: int(x) - 1, s[0::2]))\n",
    "    lengths = list(map(int, s[1::2]))\n",
    "    ends = [x + y for x, y in zip(starts, lengths)]\n",
    "    if len(shape)==3:\n",
    "        img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n",
    "    else:\n",
    "        img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n",
    "    for start, end in zip(starts, ends):\n",
    "        img[start : end] = color\n",
    "\n",
    "    return img.reshape(shape)\n",
    "\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return ' '.join(map(str, run_lengths))\n",
    "\n",
    "\n",
    "def remove_overlapping_pixels(mask, other_masks):\n",
    "    for other_mask in other_masks:\n",
    "        if np.sum(np.logical_and(mask, other_mask)) > 0:\n",
    "            mask[np.logical_and(mask, other_mask)] = 0\n",
    "    return mask\n",
    "\n",
    "def combine_masks(masks, mask_threshold):\n",
    "    \"\"\"\n",
    "    combine masks into one image\n",
    "    \"\"\"\n",
    "    maskimg = np.zeros((HEIGHT, WIDTH))\n",
    "    # print(len(masks.shape), masks.shape)\n",
    "    for m, mask in enumerate(masks,1):\n",
    "        maskimg[mask>mask_threshold] = m\n",
    "    return maskimg\n",
    "\n",
    "\n",
    "def get_box(a_mask):\n",
    "        ''' Get the bounding box of a given mask '''\n",
    "        pos = np.where(a_mask)\n",
    "        xmin = np.min(pos[1])\n",
    "        xmax = np.max(pos[1])\n",
    "        ymin = np.min(pos[0])\n",
    "        ymax = np.max(pos[0])\n",
    "        return [xmin, ymin, xmax, ymax]\n",
    "\n",
    "\n",
    "def get_filtered_masks(pred):\n",
    "    \"\"\"\n",
    "    filter masks using MIN_SCORE for mask and MAX_THRESHOLD for pixels\n",
    "    \"\"\"\n",
    "    use_masks = []   \n",
    "    for i, mask in enumerate(pred[\"masks\"]):\n",
    "\n",
    "        # Filter-out low-scoring results. Not tried yet.\n",
    "        scr = pred[\"scores\"][i].cpu().item()\n",
    "        label = pred[\"labels\"][i].cpu().item()\n",
    "        if scr > min_score_dict[label]:\n",
    "            mask = mask.cpu().numpy().squeeze()\n",
    "            # Keep only highly likely pixels\n",
    "            binary_mask = mask > mask_threshold_dict[label]\n",
    "            binary_mask = remove_overlapping_pixels(binary_mask, use_masks)\n",
    "            use_masks.append(binary_mask)\n",
    "\n",
    "    return use_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58848be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('livecell_base_preprocessing_rle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2bb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bbox\"] = df[\"bbox\"].str[1:-1]\n",
    "# [364.5894775390625, 798.4615478515625, 383.0497131347656, 798.4615478515625]\n",
    "df['bbox_sanity'] = df['bbox'].apply(lambda x: True if float(x.split()[2]) > 100 or float(x.split()[3]) > 100 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample = df[df['bbox_sanity'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample = df.groupby('image_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6190e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(one_sample['file_path'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sample['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73442d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode annotation\n",
    "HEIGHT = 520\n",
    "WIDTH = 704\n",
    "SHAPE = (HEIGHT, WIDTH)\n",
    "\n",
    "mask = rle_decode(one_sample['annotation'].iloc[0], SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c475fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_gt_pred(mask, target, pred) -> None:\n",
    "    \"\"\"\n",
    "    Print original image, ground true with segmentation masks and bounding boxes,\n",
    "    and prediction image.\n",
    "    \"\"\"\n",
    "    bbox = np.fromstring(target['bbox'], sep=' ')\n",
    "    x_min = bbox[0]\n",
    "    y_min = bbox[1]\n",
    "    w = bbox[2]\n",
    "    h = bbox[3]\n",
    "#     print(x_min, y_min, w, h)\n",
    "    \n",
    "    \n",
    "    ig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,60), facecolor=\"#fefefe\")\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(target['cell_type'])\n",
    "    ax[0].axis(\"off\")\n",
    "    \n",
    "#     masks = combine_masks(targets['masks'], 0.5)\n",
    "    #plt.imshow(img.numpy().transpose((1,2,0)))\n",
    "\n",
    "# bbox = get_box(mask)\n",
    "# x_min = bbox[0]\n",
    "# y_min = bbox[1]\n",
    "# h = bbox[3]-bbox[1]\n",
    "# w = bbox[2]-bbox[0]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#     print(x_min, y_min, w, h)\n",
    "\n",
    "    rect = patches.Rectangle((x_min, y_min), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax[1].add_patch(rect)\n",
    "    ax[1].imshow(mask)\n",
    "    # ax[1].set_title(f\"Ground truth, {len(targets['masks'])} cells\")\n",
    "    # ax[1].axis(\"off\")\n",
    "    \n",
    "    rect = patches.Rectangle((x_min, y_min), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax[2].add_patch(rect)\n",
    "    ax[2].imshow(mask)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9bb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['bbox_sanity'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    img = cv2.imread(row['file_path'])\n",
    "    mask = rle_decode(row['annotation'], SHAPE)\n",
    "    target = {'cell_type': row['cell_type'], \n",
    "              'bbox': row['bbox']}\n",
    "\n",
    "    bbox = np.fromstring(target['bbox'], sep=' ')\n",
    "    x_min = bbox[0]\n",
    "    y_min = bbox[1]\n",
    "    w = bbox[2]\n",
    "    h = bbox[3]\n",
    "    print(x_min, y_min, w, h)\n",
    "    visualise_gt_pred(mask, target, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {'cell_type': one_sample['cell_type'].iloc[0], \n",
    "          'bbox': one_sample['bbox'].iloc[0][1:-1]}\n",
    "\n",
    "visualise_gt_pred(mask, target, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
